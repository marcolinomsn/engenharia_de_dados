{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b72789a4-d169-47fe-8a0c-97feb58e906e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abfd37fc-39db-43a7-9e40-36c909d98107",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0df6509a-95b9-4869-ad27-638844e97054",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Importação de Bibliotecas\n",
    "\n",
    "Nesta célula, são importadas as bibliotecas necessárias para manipulação de dados e funções do Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42554db9-f37e-4e24-85bd-cdba20c8ba64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7947d2b4-dd46-4036-a457-fb29ee148048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### A seguir será usado o comando SQL `USE CATALOG` e `USE SCHEMA` para definir o catálogo e o schema ativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a272d015-4cfd-4227-86eb-8c738f40f2ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE CATALOG mvp\")\n",
    "spark.sql(\"USE SCHEMA bronze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31d21647-e5f9-4659-9bb7-3908ea1d5c65",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Lendo o arquivo CSV das estações com Spark e exibindo as 10 primeiras linhas, incluindo o cabeçalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fedf9ed-f121-46b7-a67d-c5aefb3aa3d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_stations = spark.read.option(\"header\", True).csv(\"/Volumes/mvp/staging/dataset/stations.csv\")\n",
    "display(df_stations.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c47da76a-83cd-4cfe-a608-8e5aeab4c6fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Escrita da tabela `stations` em formato Delta\n",
    "\n",
    "Nesta célula, o DataFrame `df_stations` é persistido no metastore do Databricks como uma **tabela Delta**, utilizando sobrescrita completa.\n",
    "- A tabela `stations` passa a existir como uma tabela Delta\n",
    "- Os dados ficam persistidos e versionados\n",
    "- A tabela pode ser consultada diretamente por SQL, notebooks ou ferramentas de BI conectadas ao Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fd72dc8-53b5-49c1-a3d2-a1b7eb485421",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_stations.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"stations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "078f5d02-e550-4953-8125-bbe7b3ccafb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Comentário da tabela `mvp.bronze.stations`\n",
    "\n",
    "Nesta célula, é definido o comentário descritivo da tabela `mvp.bronze.stations`, documentando seu propósito e principais informações armazenadas no metastore para facilitar entendimento e uso futuro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c800572-d6c2-40a5-a30d-a4dc270bf027",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    comment on table mvp.bronze.stations is\n",
    "    'The table contains information about various stations, including their geographical locations and operational details. It can be used for mapping station locations, analyzing regional coverage, and tracking the operational history of each station. Key data points include the region, state, city, and latitude/longitude coordinates.'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "504ce331-286c-4594-9286-5607a2ded1af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Comentários das colunas da tabela `mvp.bronze.stations`\n",
    "\n",
    "Nesta célula, são definidos comentários descritivos para cada coluna da tabela `mvp.bronze.stations`, documentando o significado e a finalidade de cada campo diretamente no metastore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a97e3518-87f1-4350-88b1-f610a9f86964",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "COLUMN_COMMENTS = [\n",
    "    (\"region\", \"The geographical area or zone where the station is located\"),\n",
    "    (\"state\", \"State where the station is located\"),\n",
    "    (\"city_station\", \"The city where the station is located\"),\n",
    "    (\"id_station\", \"Unique identifier assigned to each station\"),\n",
    "    (\"lat\", \"Latitude coordinate of the station location\"),\n",
    "    (\"lon\", \"Longitude coordinate of the station location\"),\n",
    "    (\"lvl\", \"Altitude of the station\"),\n",
    "    (\"record_first\", \"Date when data recording began for the station\"),\n",
    "    (\"record_last\", \"Date of the most recent station record.\"),\n",
    "]\n",
    "\n",
    "for column, comment in COLUMN_COMMENTS:\n",
    "    spark.sql(f\"comment on column mvp.bronze.stations.{column} is '{comment}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c689a6af-4e42-4047-a640-852bd6fb3fd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Inspeção do schema e metadata da tabela `mvp.bronze.stations`\n",
    "\n",
    "Nesta célula, é realizada a inspeção detalhada da tabela `mvp.bronze.stations` utilizando comandos `DESCRIBE`.\n",
    "\n",
    "Primeiro, o comando `DESCRIBE EXTENDED` é executado para obter schema e metadados completos da tabela. Em seguida, é criado um identificador auxiliar (`_id`) para permitir navegar pelas linhas do resultado e extrair o bloco de informações a partir da seção **Catalog**, exibindo apenas um subconjunto relevante dessas informações.\n",
    "\n",
    "Por fim, o comando `DESCRIBE` padrão é executado para exibir exclusivamente o schema da tabela, com foco nas colunas e seus tipos de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7ca05e8-f5b4-4d36-b01a-6add86785d91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_describe = spark.sql(\"describe extended mvp.bronze.stations\")\n",
    "df_describe = df_describe.withColumn(\"_id\", monotonically_increasing_id())\n",
    "target_id = df_describe.filter(\"col_name = 'Catalog'\").select(\"_id\").first()._id\n",
    "\n",
    "table_describe = df_describe.filter(f\"_id >= {target_id}\").limit(9)\n",
    "display(table_describe.drop(\"_id\"))\n",
    "\n",
    "display(spark.sql(\"describe mvp.bronze.stations\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ccf8b33-ebe0-4d24-b9da-f1759a9b66b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Leitura dos dados meteorológicos\n",
    "\n",
    "Nesta célula, os arquivos CSV de dados meteorológicos são carregados para um DataFrame Spark utilizando um padrão de nome (`weather_*_filtered.csv`), permitindo a leitura conjunta de múltiplos arquivos de forma automática. Em seguida, é exibida uma amostra dos dados para verificação do conteúdo carregado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8caf6c11-a9aa-4af9-8097-27faec216b2b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1766156379760}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "    #Abrindo CSVs\n",
    "df_weather_data = (\n",
    "    spark.read\n",
    "    .option(\"header\", True)\n",
    "    .csv(f\"/Volumes/mvp/staging/dataset/weather_*_filtered.csv\")\n",
    ")\n",
    "\n",
    "display(df_weather_data.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6d1a4d6-a410-4a3b-bf8e-ca0575c38e5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Padronização dos nomes das colunas\n",
    "\n",
    "Nesta célula, os nomes das colunas do DataFrame `df_weather_data` são padronizados por meio da substituição de caracteres especiais e espaços por sublinhados (`_`). Esse processo garante maior compatibilidade com Spark SQL, facilita consultas e evita problemas com caracteres não permitidos em nomes de colunas. Em seguida, é exibida uma amostra dos dados com os nomes das colunas já normalizados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "886e6fdf-c523-4ab4-b4fd-28d71f60b48c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Substituindo caracteres especiais não desejados\n",
    "df_replaced_weather_data = df_weather_data.toDF(*[col.replace(' ', '_').replace('(', '_').replace(')', '_').replace('-', '_').replace('.', '_').replace('°', '_').replace('(', '_').replace(')', '_').replace(',', '_') for col in df_weather_data.columns])\n",
    "\n",
    "display(df_replaced_weather_data.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57b4a3ef-2ddd-4ff0-bd0b-0fed6ad429a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Escrita da tabela `weather_data` em formato Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de2ae867-f5e1-469f-b5c9-17726b427652",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_replaced_weather_data.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"weather_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f99f75d-2bb3-460e-8c8c-b7ea6f066526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Comentário da tabela `mvp.bronze.weather_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13637e18-9195-430b-bfb2-bc46bff216cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    comment on table mvp.bronze.weather_data is\n",
    "    'The table contains hourly weather data collected from various stations. It includes information such as temperature, humidity, precipitation, and wind conditions. Possible use cases include analyzing weather patterns, conducting climate research, and supporting agricultural planning by understanding local weather conditions.'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66fd6708-a709-457b-86b3-c23ea678b182",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Comentários das colunas da tabela `mvp.bronze.weather_data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "585a5cab-5a75-47c4-931f-209d5a1778a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "COLUMN_COMMENTS = [\n",
    "    (\"DATA__YYYY_MM_DD_\", \"Date of the observation recorded in YYYY-MM-DD format.\"),\n",
    "    (\"Hora_UTC\", \"Hour of the observation recorded in Coordinated Universal Time (UTC)\"),\n",
    "    (\"PRECIPITAÇÃO_TOTAL__HORÁRIO__mm_\", \"Total hourly precipitation measured in millimeters\"),\n",
    "    (\"PRESSAO_ATMOSFERICA_AO_NIVEL_DA_ESTACAO__HORARIA__mB_\", \"Hourly atmospheric pressure at the station level, measured in millibars (mB)\"),\n",
    "    (\"PRESSÃO_ATMOSFERICA_MAX_NA_HORA_ANT___AUT___mB_\", \"Maximum atmospheric pressure measured in the previous hour, recorded automatically, given in millibars (mB)\"),\n",
    "    (\"PRESSÃO_ATMOSFERICA_MIN__NA_HORA_ANT___AUT___mB_\", \"Minimum atmospheric pressure recorded during the previous hour, measured in millibars.\"),\n",
    "    (\"RADIACAO_GLOBAL__KJ/m²_\", \"Amount of global radiation recorded in kilojoules per square meter\"),\n",
    "    (\"TEMPERATURA_DO_AR___BULBO_SECO__HORARIA___C_\", \"Hourly dry-bulb air temperature recorded in degrees Celsius.\"),\n",
    "    (\"TEMPERATURA_DO_PONTO_DE_ORVALHO___C_\", \"Dew point temperature in Celsius, representing the air temperature at which condensation occurs.\"),\n",
    "    (\"TEMPERATURA_MÁXIMA_NA_HORA_ANT___AUT____C_\", \"Highest air temperature recorded in the previous hour, measured in degrees Celsius\"),\n",
    "    (\"TEMPERATURA_MÍNIMA_NA_HORA_ANT___AUT____C_\", \"Lowest air temperature recorded in the preceding hour, in Celsius\"),\n",
    "    (\"TEMPERATURA_ORVALHO_MAX__NA_HORA_ANT___AUT____C_\", \"Highest dew point temperature recorded during the previous hour (°C)\"),\n",
    "    (\"TEMPERATURA_ORVALHO_MIN__NA_HORA_ANT___AUT____C_\", \"Minimum dew point temperature recorded in the previous hour, in Celsius\"),\n",
    "    (\"UMIDADE_REL__MAX__NA_HORA_ANT___AUT___%_\", \"Maximum relative humidity recorded in the previous hour as measured automatically, expressed in percent.\"),\n",
    "    (\"UMIDADE_REL__MIN__NA_HORA_ANT___AUT___%_\", \"Lowest relative humidity recorded automatically in the previous hour, expressed as percentage\"),\n",
    "    (\"UMIDADE_RELATIVA_DO_AR__HORARIA__%_\", \"Percentage of relative humidity measured for each hour\"),\n",
    "    (\"VENTO__DIREÇÃO_HORARIA__gr______gr__\", \"Hourly wind direction measured in degrees\"),\n",
    "    (\"VENTO__RAJADA_MAXIMA__m/s_\", \"Highest recorded wind gust speed during the hour, measured in meters per second\"),\n",
    "    (\"VENTO__VELOCIDADE_HORARIA__m/s_\", \"Measured wind speed per hour, expressed in meters per second\"),\n",
    "    (\"ESTACAO\", \"Station identifier where the hourly weather data was recorded\"),\n",
    "]\n",
    "\n",
    "for column, comment in COLUMN_COMMENTS:\n",
    "    spark.sql(f\"comment on column mvp.bronze.weather_data.`{column}` is '{comment}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44301957-fcbd-438e-9a85-e26769d7c990",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Inspeção do schema e metadata da tabela `mvp.bronze.weather_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b043d34a-e748-4dd3-9d2b-87ebcef0bf5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_describe = spark.sql(\"describe extended mvp.bronze.weather_data\")\n",
    "df_describe = df_describe.withColumn(\"_id\", monotonically_increasing_id())\n",
    "target_id = df_describe.filter(\"col_name = 'Catalog'\").select(\"_id\").first()._id\n",
    "\n",
    "table_describe = df_describe.filter(f\"_id >= {target_id}\").limit(9)\n",
    "display(table_describe.drop(\"_id\"))\n",
    "\n",
    "display(spark.sql(\"describe mvp.bronze.weather_data\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "mvp03-bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
